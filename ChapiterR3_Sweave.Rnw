\documentclass{report}
\usepackage{titlesec} 
\usepackage{tikz}
\usepackage[T1]{fontenc}
\usepackage{helvet}
\usepackage{colortbl}
\usepackage{eurosym}
%\usepackage{newtxtext,mathptmx}
\usepackage{xcolor}
\usepackage[inner=25mm,outer=25mm,top=30mm,bottom=20mm,headheight=13.6pt]{geometry} %marges
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{fancyhdr}
\usepackage{mathtools}
%\usepackage{graphics}
\usepackage{graphicx} 
\usepackage{color}
\usepackage{float}
\usepackage{hyperref,wasysym}
\usepackage{ulem}
\usepackage{placeins}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{color}  
\usepackage[french]{babel}  
\usepackage{graphicx}
\usepackage{subcaption}
%\usepackage[export]{adjustbox}
\usepackage{wrapfig}
\usepackage{textpos}
\usepackage{comment}
%\usepackage{fancybox}
\usepackage{lmodern} %correction d'affichage
\usepackage{csquotes} %guillemets français
\usepackage{setspace} %interligne
\usepackage{chngcntr} %compteurs modifiables
\usepackage{mathpazo}
\usepackage{amsfonts}
\usepackage{array}
\usepackage{etoolbox} %idem
\usepackage{color} %gestion des couleurs
\usepackage{setspace} %interligne
%\usepackage{natbib} %pour pouvoir ne citer que 
\usepackage{chngcntr} %compteurs modifiables
\usepackage{url} %gestion des liens hypertextes
\usepackage{blindtext} %génération de texte aléatoire : \Blindtext
\usepackage{tikz} %dessin (
\counterwithout{figure}{chapter} %permet un numérotage des figures indépendant des chapitres
\frenchspacing %adaptation normes françaises
\FrenchFootnotes %adaptation normes françaises
\setcounter{secnumdepth}{4} %chapitrage à 4 niveaux (ex: 1.2.2.3. Lorem Ipsum)
\setcounter{tocdepth}{4} % chapitrage à 4 niveaux dans le sommaire
\setlength{\parindent}{0pt}
\definecolor{LightBlue}{RGB}{66, 163, 251}
\definecolor{DarkBlue}{RGB}{36, 100, 176}
\definecolor{LightGray}{gray}{.94}
\definecolor{DarkGray}{gray}{.172}
\definecolor{Orange}{RGB}{229, 133, 3}
\definecolor{MediumBlue}{RGB}{38, 119, 193}


\newtheorem{The}{Théorème}[section]
\newtheorem{Pro}[The]{Proposition}
\newtheorem{Def}[The]{Definition}
\titleformat*{\section}{\color{DarkBlue}\normalfont\LARGE}
\titleformat*{\subsection}{\color{LightBlue}\normalfont\Large}
\titleformat*{\subsubsection}{\color{MediumBlue}\normalfont\large}

\begin{document}
\begin{titlepage}

\begin{textblock*}{1cm}(0.0005cm,-0.52cm)
\end{textblock*}
\begin{textblock*}{6cm}(9.5cm,-1.05cm)
\end{textblock*}
\begin{tikzpicture}[remember picture,overlay]
	\draw[very thick]
		([yshift=-15pt,xshift=15pt]current page.north west)--
		([yshift=-15pt,xshift=-15pt]current page.north east)--
		([yshift=15pt,xshift=-15pt]current page.south east)--
		([yshift=15pt,xshift=15pt]current page.south west)--cycle;
\end{tikzpicture}
	\textsc{\LARGE }\\[4 cm]
	\vfill
	\centering
    \vspace*{0 cm}
    \color{black}
	\textsc{\LARGE Master 2 Actuariat Parcours Data science pour l'actuariat}\\[7.8 cm]
	\textsc{\Large \textbf{Linear Regression}}\\[7.8 cm]
	\textsc{\Large \color{DarkBlue}{Cheikh Mbacké BEYE}}\\[7.8 cm]

\end{titlepage}
\tableofcontents
\newpage
\section*{Environment}
<<>>=
knitr::opts_chunk$set(echo = TRUE,
                      fig.width=12,
                      comment = NA,
                      message = FALSE,
                      warning=FALSE,
                      background="#ccffcc"
                      )
@


<<>>=
library(dplyr)
library(tidyr)
library(ggplot2)
library(fst)
library(readr)
@


\section*{ LINEAR REGRESSION}

Linear regression is a very simple approach for supervised learning. In particular, linear regression is useful tool for predicting a quantitative response. 
The data set used in this part is the $Advertising$ data. It describes sales( in thousand of units) for a particular product as  function of advertising budgets (in thousand of dollars) for $TV$, $Radio$ and $Newspaper$ media.
Suppose that our role as data scientist is the answer the following questions based in $Advertising$ data.
\begin{enumerate}
\item is there a relationship between advertising budget and sales?
 Our first goal should be to determine whether the data provide evidence of an association between advertising expenditure and sales. If the evidence is weak, the one might argue that no money should be spent on advertising.\\
 
\item How strong is the relationship between advertising budget and sales?
  Assuming that there is a relationship between advertising budget and sales, we would like to know how strong is the relationship. In other words, given a certain advertising budget, can we predict sales accurately? 
  
  
\item Which media contributes to sales?
Do all three media: $TV$, $Radio$ and $Newspaper$ contribute to sales or do just one or two of the media contribute?  To answer the question, we must find a way to separate out the individual effects of each medium when we have spent money on all three media.

\item 4 How accurately can we estimate the effect of each of medium on sales?
For every dollar spent on advertising in a particular medium, by what amount will sales increase? How accurately can we predict this amount of increase?

\item 5 How accurately can we predict future sales?
For any given level of television, radio or newspaper advertising, what is our prediction for sales and what is the accuracy of this prediction?

\item 6 Is the relation linear ?
If there is approximatively a straight-line relationship between advertising expenditure in the various media and sales, then linear regression is an appropriate tool. If not, then it may still possible to transform the predictor or the response so that linear regression can be used.

\item Is there a synergy among the advertising media?
Perhaps spending $\$50,000$ on television advertising and $\$50,000$ on radio advertising results in more sales than allocating $\$100,000$ to either television or radio individualy. This situation is known as $interaction$ effect.
\end{enumerate}
\subsection*{Simple regression} 

Simple regression lives up its name: it's a very straightforward approach for predicting a quantitative response $Y$ on the basis of a single predictor variable $X$. It assumes that there is a linear relationship between $X$ and $Y$. Mathematically, we can write this linear relationship as follow 
$$ Y\approx \beta_0+\beta_1 X$$
$\beta_0$ and $\beta_1$ are unknown: $\beta_0$ represents the intercept and $\beta_1$ the slope in the linear model. These values are known as the model parameters or coefficients.
Once we have used our training data to produce estimates $\widehat{\beta_0}$ and $\widehat{\beta}_1$ for the model coefficients, we can predict future value $\widehat{y}$ of $Y$ on the basis of a particular value, $x$ of $X$ by computing 
$$y= \widehat{\beta_0}+\widehat{\beta_1} x$$

The main purpose is the computation of the straight line which is as close as possible of data points.
The must common approach involves the $least~square$ criterion.

Let $\widehat{y_i}=\widehat{\beta_0}+\widehat{\beta_1}x_i$ be the prediction for $Y$ based on the $i$th value of $X$ . Then $e_i=y_i-\widehat{y_i}$ represents the $i$th residual; this is the difference between the observed response value and the $i$th response value predicted by our linear model.
The Residual Sum of Squares (RSS) is defined as follow
$$RSS=\sum_{i=1}^{n}\big(y_i- \widehat{\beta_0}+\widehat{\beta_1} x_i\big)^2$$
The least square approach chooses $\beta_0$ and $\beta_1$ to minimize the RSS.
We can easily demonstrate that the minimizers are defined as follow

$$\beta_1=\frac{\sum_{i=1}^{n}\big(y_i-\bar{y}\big)\big(x_i-\bar{x}\big)}{\sum_{i=1}^{n}\big(x_i-\bar{x}\big)^2}$$

$$\beta_0=\bar{y}-\beta_1\bar{x}$$

\subsubsection*{Data Import and treatment} 
<<>>=
Advertising <- read_csv('Advertising.csv')
str(Advertising)
par(mfrow=c(1,3))
with(Advertising,
     plot(TV,Sales,pch=19,frame.plot = F)
    )
with(Advertising,
     plot(Radio,Sales,pch=19,frame.plot = F)
    )
with(Advertising,
     plot(Newspaper,Sales,pch=19,frame.plot = F)
    )
@

The centroid of the  $(x_i,y_i)$ points is one of the straight line .
<<>>=
attach(Advertising)
(beta1_TV=cov(Sales,TV)/var(TV))
(beta0_TV=mean(Sales)-beta1_TV*mean(TV))
(beta1_Radio=cov(Sales,Radio)/var(Radio))
(beta0_Radio=mean(Sales)-beta1_Radio*mean(Radio))
(beta1_Newspaper=cov(Sales,Newspaper)/var(Newspaper))
(beta0_Newspaper=mean(Sales)-beta1_Newspaper*mean(Newspaper))
SalesTV_hat=beta1_TV*TV+beta0_TV
SalesRadio_hat=beta1_Radio*Radio+beta0_Radio
SalesNewspaper_hat=beta1_Newspaper*Newspaper+beta0_Newspaper
par(mfrow=c(1,3))
plot(TV,
     Sales,
     pch=19,
     frame.plot = FALSE
     )
abline(b=beta1_TV,
       a=beta0_TV,
       col='tomato4',
       lwd=3
       )
abline(h=mean(Sales),
       lty=2,
       col='light blue',
       lwd=2
       )
abline(v=mean(TV),
       lty=2,
       col='light blue',
       lwd=2
       )
plot(Radio,
     Sales,
     pch=19,
     frame.plot = FALSE
     )
abline(b=beta1_Radio,
       a=beta0_Radio,
       col='tomato4',
       lwd=3
       )
abline(h=mean(Sales),
       lty=2,
       col='light blue',
       lwd=2
       )
abline(v=mean(Radio),
       lty=2,
       col='light blue',
       lwd=2
       )
plot(Newspaper,
     Sales,
     pch=19,
     frame.plot = FALSE
     )
abline(b=beta1_Newspaper,
       a=beta0_Newspaper,
       col='tomato4',
       lwd=3
       )
abline(h=mean(Sales),
       lty=2,
       col='light blue',
       lwd=2
       )
abline(v=mean(Newspaper),
       lty=2,
       col='light blue',
       lwd=2
       )
@

R base has a $lm(Y \sim X)$ method which computes linear regression of the couple $(X,Y)$.
<<>>=
(reg_TV <- lm(Sales~TV,data = Advertising))
(reg_Radio <- lm(Sales~Radio,data = Advertising))
(reg_Newspaper <- lm(Sales~Newspaper,data = Advertising))
par(mfrow=c(1,3))
plot(TV,
     Sales,
     pch=19,
     frame = FALSE
     )
abline(reg_TV,
       col='purple',
       lwd=2
       )
segments(TV,Sales,TV,SalesTV_hat,col="tomato4")
plot(Radio,
     Sales,
     pch=19,
     frame.plot = FALSE
     )
abline(reg_Radio,
       col='purple',
       lwd=2
       )
segments(Radio,Sales,Radio,SalesRadio_hat,col="tomato4")
plot(Newspaper,
     Sales,
     pch=19,
     frame.plot = FALSE
     )
abline(reg_Newspaper,
       lwd=2,
       col='purple'
       )
segments(Newspaper,Sales,Newspaper,SalesNewspaper_hat,col="tomato4")
@
<<>>=
RSS=function(beta)
{
  sum((Sales-(beta[1]+beta[2]*TV))^2)
}
x <-c(seq(0,9,1),seq(0,9,1))

RSS_vect=Vectorize(RSS)
func=RSS_vect(x)
outopti <- optimization::optim_nm(RSS,
                                  k=2,
                                  start = c(0,9),
                                  trace = T
                                  )
plot(outopti,frame=FALSE)
plot(outopti,'contour')
 points(7.03259,
                                    0.04754,
                                    type = 'b',
                                    col="red",
                                    pch=19
                                    )
ContourFunctions::cf_func(RSS,
                          xlim = c(0,9),
                          ylim = c(0,1),
                          color.palette=terrain.colors,
                          with_lines=T,
                          bar=T,
                          afterplotfunc=function()
                            {
                              points(7.03259,
                                    0.04754,
                                    type = 'b',
                                    col="red",
                                    pch=19
                                    )
                             }
                          )
@
As expected the $RSS$ function reach its minimum at $(\widehat{\beta_0},\widehat{\beta_1})$. The red dot represents $(\widehat{\beta_0},\widehat{\beta_1})=(7.03259,~0.04754)$.
$\widehat{\beta_1}$ and $\widehat{\beta_1}$ are respectively approximation of $\beta_1$ and $\beta_0$ . The question is: how accurately do they approximate the parameters?
\end{document}
